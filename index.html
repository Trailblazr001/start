<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🚀</text></svg>">
    <title>LLM Trailblazers' Community</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito+Sans:wght@400;700&family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
    <style>
        body {
            font-family: 'Nunito Sans', sans-serif;
            line-height: 1.8;
            background-color: #0a0a2a;
            color: #ffffff;
            margin: 0;
            padding: 0;
        }

        .fullscreen {
            min-height: 100vh;
            padding: 20px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            text-align: center;
            box-sizing: border-box;
        }

        .title {
            font-family: 'Orbitron', sans-serif;
            font-size: 3em;
            text-shadow: 0 0 10px #00ffff, 0 0 20px #00ffff, 0 0 30px #00ffff;
            margin-bottom: 20px;
        }

        .subtitle {
            font-family: 'Orbitron', sans-serif;
            font-size: 1.5em;
            margin-bottom: 20px;
        }

        .content {
            padding: 0 20px;
            max-width: 800px;
            margin: auto;
        }

        h1 {
            font-size: 2.5em;
            font-family: 'Orbitron', sans-serif;
            margin-bottom: 20px;
            text-shadow: 0 0 10px #00ffff;
        }

        h2 {
            color: #00ffff;
            font-family: 'Orbitron', sans-serif;
        }

        a {
            color: #ff00ff;
            text-decoration: underline;
        }

        #dynamic-question {
            font-size: 1.2em;
            margin-bottom: 20px;
            color: #00ffff;
        }

        .cta-button {
            background-color: #00ffff;
            color: #0a0a2a;
            border: none;
            padding: 12px 24px;
            font-size: 1em;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 20px auto;
            display: block;
            border-radius: 5px;
        }

        .cta-button:hover {
            background-color: #ffffff;
            box-shadow: 0 0 20px #00ffff;
        }

        #timer {
            font-size: 1em;
            margin-top: 20px;
        }

        form {
            margin-top: 20px;
            display: none;
        }

        input, textarea {
            width: 100%;
            padding: 10px;
            margin-bottom: 10px;
            background-color: rgba(255, 255, 255, 0.1);
            border: 1px solid #00ffff;
            color: #ffffff;
            border-radius: 5px;
            box-sizing: border-box;
        }

        .emoji {
            font-size: 2em;
            margin: 0 auto 20px;
        }

        .left-aligned-list {
            text-align: left;
            padding-left: 0;
            list-style-position: inside;
        }

        .centered-container {
            text-align: center;
            margin: 40px auto;
            max-width: 800px;
        }

        @media (max-width: 768px) {
            .title, h1 {
                font-size: 2em;
            }
            .subtitle, #dynamic-question, .cta-button, #timer, .content {
                font-size: 1em;
            }
            .content, .fullscreen {
                padding: 10px;
            }
            }
        pre {
            background-color: black;
            border: 1px solid #ddd;
            border-left: 3px solid #00ffff;
            color: #666;
            page-break-inside: avoid;
            font-family: monospace;
            font-size: 15px;
            line-height: 1.6;
            margin-bottom: 1.6em;
            max-width: 100%;
            overflow: auto;
            padding: 0.5em 0.5em 0.5em 0.5em;
            display: block;
            word-wrap: break-word;
        }
        
        code {
            font-family: 'Courier New', Courier, monospace;
            color: white;
        }
        
        .language-plaintext {
            color: #01a252;
        }
        .collapsible {
            background-color: #f1f1f1;
            font-family: 'Orbitron', sans-serif;
            color: #444;
            cursor: pointer;
            padding: 18px;
            width: 100%;
            border: none;
            text-align: left;
            outline: none;
            font-size: 15px;
            }

        .active, .collapsible:hover {
            background-color: #ccc;
            }

        .peek-content {
            padding: 0 18px;
            display: none;
            overflow: hidden;
            background-color: #f9f9f9;
            }

        .collapsible:after {
            content: '\f06e'; /* Unicode for eye icon */
            font-family: 'Font Awesome 5 Free';
            font-weight: 900;
            float: right;
            margin-left: 5px;
        }

        .active:after {
            content: '\f070'; /* Unicode for eye-slash icon */
        }
        .dark-text {
            color: black;
        }
        .btn {
            margin-top: 16px;
            text-transform: uppercase;
            font-size: 14px;
            text-decoration: none;
            cursor: pointer;
            display: inline-block;
            padding: 10px;
            font-family: inherit;
            text-shadow: none;
            user-select: none;
            transition: all .1s ease-in;
            background-color: #0a0a2a;
            border: 1px solid #0a0a2a;
            color: #ffffff;
        }
        #overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.7);
            z-index: 999;
        }
        #formIframe {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1000;
            width: 80%;
            max-width: 600px;
            height: 90%;
            max-height: 600px;
        }

        #formIframe iframe {
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>

    <script src="https://form.jotform.com/static/feedback2.js" type="text/javascript"></script>
    <script type="text/javascript">
        var JFL_242242239521348 = new JotformFeedback({
            formId: '242242239521348',
            base: 'https://form.jotform.com/',
            windowTitle: 'Take me to LLM Trailblazers!',
            backgroundColor: '#0a0a2a',
            fontColor: '#ffffff',
            type: '2',
            height: 500,
            width: 700,
            openOnLoad: false
        });
    </script>
    <script src='https://cdn.jotfor.ms/s/umd/latest/for-form-embed-handler.js'></script>

</head>
<body>
    <div class="fullscreen">
        <h1>LLM Trailblazers' Community 🚀</h1>
        <div id="dynamic-question"></div>
        <button class="cta-button" onclick="openFormPopup('upper')">Trailblaze LLMs from Scratch 🌟</button>
        <div class="emoji">🤖 🧠 💡</div>
        <div id="timer"></div>
    </div>
    <!-- Course Description Sections -->
    <div class="content">
        <h2>For Whom</h2>
            <ul class="left-aligned-list">
                <p>
                    Join if you want to be with:
                </p>
                <li>AI enthusiasts eager to build confidence when working with LLMs and take their understanding to a deeper level</li>
                <li>Software engineers, years apart from their first commit, now ready to navigate the landscape of AI applications</li>
                <li>Data Engineers with hands-on data experience, looking to unlock new projects that bridge the gap to Data Science</li>
                <li>Individuals who understand that current investments and interest in AI will be utilized by someone, and want to ensure that someone is them - taking control of their own AI journey and future-proofing their skills</li>
            </ul>
        <h2>What You'll Learn</h2>
            <ul class="left-aligned-list">
                <p>
                    Our 8-week Accelerator program takes you on a comprehensive journey through Large Language Models. Here's what you'll learn each week:
                </p>
                <li>
                    <strong>Week 1: "LLM-s 101" - Understanding Large Language Models</strong>
                    <p>Explore how LLMs differ from other ML models and set up your first data loading pipeline.</p>
                </li>
                <li>
                    <strong>Week 2: "Turning Words into Tokens" - Working with Text Data</strong>
                    <p>Learn to build data pipelines for LLMs and train a BPE tokenizer from scratch.</p>
                </li>
                <li>
                    <strong>Week 3: "Attention, Please!" - Coding Attention Mechanisms</strong>
                    <p>Dive into attention mechanisms and understand where decoder and encoder architectures diverge.</p>
                </li>
                <li>
                    <strong>Week 4: "GPT from Scratch" - Implementing Your Own Transformer Model</strong>
                    <p>Build a GPT model from the ground up, complete with training whistles and bells.</p>
                </li>
                <li>
                    <strong>Week 5: "Pretraining Powerhouse" - Unleashing Unlabeled Data</strong>
                    <p>Explore pretraining on unlabeled data and understand the impact of context size.</p>
                </li>
                <li>
                    <strong>Week 6: "Changing LLM Behavior" - Fine-tuning Techniques</strong>
                    <p>Master fine-tuning for text classification and and domain adaptation with continued pre-training, PEFT and LoRA revisited.</p>
                </li>
                <li>
                    <strong>Week 7: "InstructGPT" - Letting LLM-s Follow Instructions</strong>
                    <p>Dive deeper into how conversational chatbots are different from LLM-s.</p>
                </li>
                <li>
                    <strong>Week 8: "Build and Innovate" - Bringing Your Ideas to Life</strong>
                    <p>Apply your newfound skills to build an innovative project, either solo or with a pair programming buddy.</p>
                </li>
            </ul>

            <h2>How</h2>
            <p>
                Our 8-week Accelerator Circle is designed to fit into your busy schedule, requiring only 2-3 hours of commitment per week. The program is built on top of the following high-quality resources:
            </p>
            <ul class="left-aligned-list">
                <li><a href="https://sebastianraschka.com/books/#build-a-large-language-model-from-scratch">Book "LLMs from Scratch" by Sebastian Raschka</a></li>
                <li><a href="https://www.youtube.com/@AndrejKarpathy">Video Materials from Andrej Karpathy</a></li>
                <li><a href="https://www.deeplearningbook.org/">Book "Deep Learning" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</a></li>
                <li><a href="https://www.deeplearning.ai/">Deeplearning.ai Materials from Andrew Ng</a></li>
            </ul>
            <h3>What are you getting from our community:</h3>
            <ul>
                <li>Goal setting and progress check-in in the middle of the course</li>
                <li>Final review of the next steps as a touchpoint on the project to build at the end of the course</li>
                <li>Weekly reminders on the week's content, if you opt in</li>
                <li>Small class size for a closer learning experience</li>
                <li>Online chat with participants for Q&A and aligning on understanding</li>
                <li>Community study with boosted engagement and motivation</li>
                <li>Bi-weekly sessions on practical topics such as RAG, Agents, data security, Responsible AI, instruction fine-tuning, and application system design</li>
                <li>Interactive quizzes to ensure comprehension and assess progress (not just for grades, but to ensure understanding)</li>
            </ul>

            <div class="collapsible-section">
                <button class="collapsible">Peek Under The Hood: TinyGPT in Action</button>
                <div class="peek-content">
                    <pre><code class="language-python">
                    import torch
                    import torch.nn as nn

                    class TinyGPT(nn.Module):
                        def __init__(self):
                            super().__init__()
                            self.embedding = nn.Embedding(1000, 16)
                            self.transformer = nn.TransformerEncoder(
                                nn.TransformerEncoderLayer(16, 2), 1
                            )
                            self.fc = nn.Linear(16, 1000)
                        
                        def forward(self, x):
                            return self.fc(self.transformer(self.embedding(x)))

                    # Let's try it out!
                    model = TinyGPT()
                    input_text = "ready to trailblaze?"
                    input_tokens = torch.tensor([[1, 2, 3]])  # Pretended tokens

                    output = model(input_tokens)
                    print(f"Input: {input_text}")
                    print(f"Output shape: {output.shape}")
                    </code></pre>
                    <p class="dark-text">Output:</p>
                    <pre><code class="language-plaintext">
                    Input: ready to trailblaze?
                    Output shape: torch.Size([1, 3, 1000])
                    </code></pre>
                    <p class="dark-text">
                        This TinyGPT model demonstrates the basic structure of a GPT. What's happening?
                    </p>
                    <ul class="dark-text">
                        <li>We input the phrase "ready to trailblaze?" tokenized as [1, 2, 3] for simplicity.</li>
                        <li>The output shape [1, 3, 1000] means:
                            <ul>
                                <li>1: We're processing one batch (one input sequence)</li>
                                <li>3: The model produces output for each of the 3 input words</li>
                                <li>1000: For each word, it predicts probabilities for 1000 potential next words</li>
                            </ul>
                        </li>
                    </ul>
                    <p class="dark-text">
                        In a full-sized GPT, this output would be used to predict the most likely next word in the sequence. It's like the model is constantly asking, "What comes next?" for every word it sees!
                    </p>
                    <p class="dark-text">
                        Join us to dive deeper into building and understanding these fascinating models!
                    </p>
                </div>
            </div>
        </div>
    </div>

    <div class="centered-container">
        <h2>Are you with us?</h2>
    </div>

    <div class="centered-container">
        <div id="formContainer">
            <button class="cta-button" onclick="openFormPopup('lower')">Join LLM Trailblazers 🌟</button>
            <div class="emoji">🤖 🧠 💡</div>
        </div>
    </div>

    <script>
        window.jotformEmbedHandler("iframe[id='JotFormIFrame-242242239521348']", "https://form.jotform.com/")
        function openFormPopup(buttonType) {
            window.open('https://form.jotform.com/242242239521348', 'LLM_Trailblazers_Form', 'scrollbars=yes, toolbar=no, width=700, height=500');
            
            if (buttonType === 'upper') {
                setTimeout(() => {
                    document.getElementById('formContainer').scrollIntoView({ behavior: 'smooth' });
                }, 100);
            }
        }

        const questions = [
            "Feeling like AI progress is leaving you behind? 🏃‍♂️💨",
            "Want to truly understand how LLMs work? 🧐🔍",
            "Overwhelmed by the flood of AI learning resources? 🌊📚",
            "Want to unlock new exciting projects and be an AI thought leader? 🚀💼",
            "Willing to build LLM-powered applications with confidence? 💪🔓"
        ];

        function changeQuestion() {
            const questionElement = document.getElementById('dynamic-question');
            questionElement.textContent = questions[Math.floor(Math.random() * questions.length)];
        }

        setInterval(changeQuestion, 2000);
        changeQuestion(); // Initial question

        // Set the date we're counting down to
        const countDownDate = new Date("Sep 2, 2024 00:00:00").getTime();

        function updateTimer() {
            const now = new Date().getTime();
            const distance = countDownDate - now;

            const days = Math.floor(distance / (1000 * 60 * 60 * 24));
            const hours = Math.floor((distance % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60));
            const minutes = Math.floor((distance % (1000 * 60 * 60)) / (1000 * 60));
            const seconds = Math.floor((distance % (1000 * 60)) / 1000);

            document.getElementById("timer").innerHTML = `Next cohort starts in: ${days}d ${hours}h ${minutes}m ${seconds}s`;

            if (distance < 0) {
                clearInterval(x);
                document.getElementById("timer").innerHTML = "EXPIRED";
            }
        }
        
        setInterval(updateTimer, 1000);
        updateTimer(); // Initial timer update
        
        // Peek under the Hood collapsible
        var coll = document.getElementsByClassName("collapsible");
        var i;

        for (i = 0; i < coll.length; i++) {
        coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
            content.style.display = "none";
            this.style.backgroundColor = "#f1f1f1";
            } else {
            content.style.display = "block";
            this.style.backgroundColor = "#e7e7e7";
            }
        });
        }
    </script>
</body>
</html>
